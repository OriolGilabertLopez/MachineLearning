{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRCvj8pmzXGm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLM-xO4KzW83"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pathlib\n",
    "import time\n",
    "import IPython.display as display\n",
    "import random\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from google.colab import drive\n",
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "PLT4P0UhV3xc",
    "outputId": "6161fe41-2346-4252-85fc-112e69838699",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/gdrive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def timer(start,end):\n",
    "    hours, rem = divmod(end - start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    result = str(\"{:0>2}h:{:0>2}m:{:05.2f}s\".format(int(hours),int(minutes),seconds))\n",
    "    return result \n",
    "\n",
    "\n",
    "Start_time_Scrpit1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4No3eHWei-8z"
   },
   "outputs": [],
   "source": [
    "\n",
    "h_pixels = w_pixels = 100\n",
    "\n",
    "\n",
    "# preprocesar imatges normals\n",
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels = 1)             \n",
    "  image = tf.image.resize_images(image, [h_pixels, w_pixels])\n",
    "  image /= 255.0  # normalitzem al rang [0, 1]\n",
    "  \n",
    "  return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "    \n",
    "  return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wwOJ6BN5vI39"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/gdrive/My Drive/Data_Aug/')  #change dir\n",
    "\n",
    "# !mkdir train\n",
    "# !mkdir test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UFRtDxXnvIb0"
   },
   "outputs": [],
   "source": [
    "# !unzip train.zip -d train/\n",
    "# !unzip test.zip -d test/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-8P-WaQ_IkT"
   },
   "outputs": [],
   "source": [
    "\n",
    "def Mirroring_Data_Generator(IP):\n",
    "  \n",
    "  for x in range(len(IP)): \n",
    "    im_path = IP[x]\n",
    " \n",
    "    if(str.find(im_path, \"train/PNEUMONIA\") > 0):\n",
    "      print(str(x + 1) + \"/5211.\\t train/PNEUMONIA\")   \n",
    "      mat = cv2.flip(cv2.imread(im_path), 1)     # 1 = horitzontal\n",
    "      im = Image.fromarray(mat)\n",
    "      im.save(\"/content/gdrive/My Drive/Data_Aug/train/train/PNEUMONIA/data_aug\" + str(x)  + \".jpeg\")\n",
    "\n",
    "    elif(str.find(im_path, \"train/NORMAL\") > 0):\n",
    "      print(str(x + 1) + \"/5211.\\t train/NORMAL\")\n",
    "      mat = cv2.flip(cv2.imread(im_path), 1)\n",
    "      im = Image.fromarray(mat)\n",
    "      im.save(\"/content/gdrive/My Drive/Data_Aug/train/train/NORMAL/data_aug\" + str(x)  + \".jpeg\")\n",
    "\n",
    "    elif(str.find(im_path, \"test/PNEUMONIA\") > 0):\n",
    "      print(str(x + 1) + \"/624.\\t test/PNEUMONIA\")\n",
    "      mat = cv2.flip(cv2.imread(im_path), 1)\n",
    "      im = Image.fromarray(mat)\n",
    "      im.save(\"/content/gdrive/My Drive/Data_Aug/test/test/PNEUMONIA/data_aug\" + str(x)  + \".jpeg\")\n",
    "\n",
    "    elif(str.find(im_path, \"test/NORMAL\") > 0):\n",
    "      print(str(x + 1) + \"/624.\\t test/NORMAL\")\n",
    "      mat = cv2.flip(cv2.imread(im_path), 1)\n",
    "      im = Image.fromarray(mat)\n",
    "      im.save(\"/content/gdrive/My Drive/Data_Aug/test/test/NORMAL/data_aug_\" + str(x)  + \".jpeg\")\n",
    "\n",
    "    else:\n",
    "      None\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFtMvirOATwN"
   },
   "outputs": [],
   "source": [
    "#Mirroring_Data_Generator(train_image_paths)\n",
    "#Mirroring_Data_Generator(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "colab_type": "code",
    "id": "l0W76v7erU9X",
    "outputId": "8e280836-9497-4624-b3a6-1180204976dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir: /content/gdrive/My Drive/Data_Aug/train/train\n",
      "Test dir: /content/gdrive/My Drive/Data_Aug/test/test\n",
      "Primera imatge Train:\t/content/gdrive/My Drive/Data_Aug/train/train/PNEUMONIA/data_aug211.jpeg\n",
      "Primera imatge Test:\t/content/gdrive/My Drive/Data_Aug/test/test/PNEUMONIA/data_aug186.jpeg\n",
      "\n",
      "\n",
      "Nombre d'imatges Train:\t10422\n",
      "Nombre d'imatges Test:\t1248\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DirectoriDades_aug = pathlib.Path('/content/gdrive/My Drive/Data_Aug')\n",
    "train_dir_aug = DirectoriDades_aug / 'train' / 'train/'\n",
    "test_dir_aug  = DirectoriDades_aug / 'test'/ 'test/'\n",
    "\n",
    "\n",
    "print(\"Train dir: {}\".format(train_dir_aug))\n",
    "print(\"Test dir: {}\".format(test_dir_aug))\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(pathlib.Path(train_dir_aug))\n",
    "train_image_paths_aug = list(train_dir_aug.glob('*/*.jpeg'))\n",
    "train_image_paths_aug = [str(path) for path in train_image_paths_aug]\n",
    "\n",
    "random.shuffle(train_image_paths_aug)\n",
    "train_image_count_aug = len(train_image_paths_aug)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(test_dir_aug)\n",
    "test_image_paths_aug = list(test_dir_aug.glob('*/*.jpeg'))\n",
    "test_image_paths_aug = [str(path) for path in test_image_paths_aug]\n",
    "\n",
    "random.shuffle(test_image_paths_aug)\n",
    "test_image_count_aug = len(test_image_paths_aug)\n",
    "\n",
    "\n",
    "print(\"Primera imatge Train:\\t{}\".format(train_image_paths_aug[0]))\n",
    "print(\"Primera imatge Test:\\t{}\".format(test_image_paths_aug[0]))\n",
    "print(\"\\n\")\n",
    "print(\"Nombre d'imatges Train:\\t{}\".format(train_image_count_aug))\n",
    "print(\"Nombre d'imatges Test:\\t{}\".format(test_image_count_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-KxmRg7wsFo"
   },
   "source": [
    "## Funci贸 Data Augemtation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "werLhOOoGHmb"
   },
   "outputs": [],
   "source": [
    "def Define_model(capes, epoques, h_pixels, w_pixels, DropOut, NumMod):\n",
    "\n",
    "\n",
    "                                                                                      \n",
    "  \n",
    "  print('\\n\\n\\n\\n\\n\\n#################################################################')\n",
    "  print('\\t\\t MODEL:\\t\\t'+ str(NumMod))\n",
    "  print('\\t\\t CAPES:\\t\\t'+ str(capes))\n",
    "  print('\\t\\t EPOQUES:\\t'+ str(epoques))\n",
    "  print('\\t\\t PIXELS:\\t(' + str(h_pixels) + ',' +  str(w_pixels)+ ')')\n",
    "  print('#################################################################')\n",
    "  \n",
    "  \n",
    "  callbacks = [keras.callbacks.EarlyStopping( monitor = 'val_loss',\n",
    "                                              min_delta = 1e-2,\n",
    "                                              patience = 2,\n",
    "                                              verbose = 1)]\n",
    "\n",
    "  start_time = time.time()\n",
    "  \n",
    "  train_roc_auc_list = []\n",
    "  test_roc_auc_list  = []\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  Percent_Data = np.arange(0.1, 1.1, 0.1)\n",
    "  iteration = 1  \n",
    "  \n",
    "  for i in Percent_Data:\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    train_image_paths_aug2  = random.choices(train_image_paths_aug, k = int(train_image_count_aug * i))    # Afame el i% de les imatges train \n",
    "    test_image_paths_aug2   = random.choices(test_image_paths_aug, k = int(test_image_count_aug * i))       # Afame el i% de les imatges test\n",
    "\n",
    "    label_names_aug = sorted(item.name for item in train_dir_aug.glob('*/') if item.is_dir())\n",
    "    label_to_index_aug = dict((name, index) for index, name in enumerate(label_names_aug))\n",
    "\n",
    "\n",
    "    train_image_labels_aug = [label_to_index_aug[pathlib.Path(path).parent.name] for path in train_image_paths_aug2] \n",
    "    test_image_labels_aug  = [label_to_index_aug[pathlib.Path(path).parent.name] for path in test_image_paths_aug2 ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    auto = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "    train_path_ds_aug = tf.data.Dataset.from_tensor_slices(train_image_paths_aug2)\n",
    "    test_path_ds_aug  = tf.data.Dataset.from_tensor_slices(test_image_paths_aug2)\n",
    "    \n",
    "    \n",
    "    train_image_ds_aug = train_path_ds_aug.map(load_and_preprocess_image, num_parallel_calls = auto)\n",
    "    test_image_ds_aug  = test_path_ds_aug.map(load_and_preprocess_image, num_parallel_calls = auto)\n",
    "\n",
    "  \n",
    "    train_label_ds_aug = tf.data.Dataset.from_tensor_slices(tf.cast(train_image_labels_aug, tf.int64))\n",
    "    test_label_ds_aug  = tf.data.Dataset.from_tensor_slices(tf.cast(test_image_labels_aug, tf.int64))\n",
    "\n",
    "    train_image_label_ds_aug = tf.data.Dataset.zip((train_image_ds_aug, train_label_ds_aug))\n",
    "    test_image_label_ds_aug  = tf.data.Dataset.zip((test_image_ds_aug, test_label_ds_aug))\n",
    "\n",
    "    \n",
    "    batch_size = 16\n",
    "\n",
    "    train_ds = train_image_label_ds_aug.shuffle(buffer_size = train_image_count_aug)\n",
    "    train_ds = train_ds.repeat()\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    train_ds = train_ds.prefetch(buffer_size = batch_size)\n",
    "\n",
    "    train_ds = test_image_label_ds_aug.shuffle(buffer_size = test_image_count_aug)\n",
    "    test_ds = test_image_label_ds_aug.repeat()\n",
    "    test_ds = test_ds.batch(batch_size)\n",
    "    test_ds = test_ds.prefetch(buffer_size=16)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "\n",
    "    if(capes == 5): \n",
    "      print(\"\\nCapes 5: (32, 32) + (64, 64) + FDD\")        \n",
    "      model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding=\"same\", input_shape=(h_pixels, w_pixels, 1)))\n",
    "      model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "      #model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "      model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "      model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "      m#odel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "      if(DropOut == 'Yes'):\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "      else:\n",
    "        None\n",
    "\n",
    "      model.add(tf.keras.layers.Flatten())\n",
    "      model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "      model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "    elif(capes == 6): \n",
    "      print(\"\\nCapes 6: (32, 32) + (64, 64) + (128) + FDD\")        \n",
    "      model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding=\"same\", input_shape=(h_pixels, w_pixels, 1)))\n",
    "      model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "      #model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "      model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "      model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "      #model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "      model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "      if(DropOut == 'Yes'):\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "      else:\n",
    "        None\n",
    "      model.add(tf.keras.layers.Flatten())\n",
    "      model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "      model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer = \"adam\", \n",
    "                  loss = \"binary_crossentropy\", \n",
    "                  metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "     \n",
    "    if(iteration == 1):\n",
    "      model.summary()    \n",
    "    else:\n",
    "      None\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    train_steps_per_epoch = len(train_image_paths_aug) / batch_size\n",
    "    test_steps_per_epoch  = len(test_image_paths_aug)  / batch_size\n",
    "\n",
    "\n",
    "\n",
    "    print('\\n\\n=================================================================') \n",
    "    print('      E N T R E N A M E N T     D E L      M O D E L     ' + str(NumMod))\n",
    "    print(\"                  -----------------------\")\n",
    "    print(\"                      Iteraci贸  {} / {}\".format(iteration, len(Percent_Data)))\n",
    "    print('=================================================================\\n')\n",
    "\n",
    "\n",
    "\n",
    "    model.fit(train_ds,\n",
    "              steps_per_epoch = int(train_steps_per_epoch), \n",
    "              validation_data = test_ds, \n",
    "              validation_steps = int(test_steps_per_epoch),\n",
    "              callbacks = callbacks,\n",
    "              epochs = epoques)\n",
    "\n",
    "\n",
    "\n",
    "    y_train_pred = model.predict(train_image_label_ds_aug.batch(batch_size), steps=int(train_steps_per_epoch))\n",
    "    y_train = np.array(train_image_labels_aug)\n",
    "\n",
    "    y_test_pred = model.predict(test_image_label_ds_aug, steps=int(test_steps_per_epoch))\n",
    "    y_test = np.array(test_image_labels_aug)\n",
    "\n",
    "    print(len(y_train_pred))\n",
    "    print(len(y_train))\n",
    "    print(len(y_test_pred))\n",
    "    print(len(y_test))\n",
    "\n",
    "\n",
    "\n",
    "    train_fpr, train_tpr, _ = roc_curve(y_train, y_train_pred)\n",
    "    train_roc_auc = auc(train_fpr, train_tpr)\n",
    "\n",
    "    test_fpr, test_tpr, _ = roc_curve(y_test, y_test_pred)\n",
    "    test_roc_auc = auc(test_fpr, test_tpr)\n",
    "    \n",
    "    train_roc_auc_list.append(train_roc_auc)\n",
    "    test_roc_auc_list.append(test_roc_auc)\n",
    "    \n",
    "    print('AUC train vect:' + str(train_roc_auc_list))\n",
    "    print('AUC test vect:'  + str(test_roc_auc_list))\n",
    "    \n",
    "    print('AUC train :' + str(train_roc_auc))\n",
    "    print('AUC test :'  + str(test_roc_auc))\n",
    "  \n",
    "    iteration = iteration + 1\n",
    "   \n",
    "  \n",
    "  runtime_model = timer(start_time, time.time())\n",
    "  print(\"\\nTemps d'execuci贸: %s\" % runtime_model)\n",
    "  \n",
    "  globals().update(locals())\n",
    "\n",
    "  \n",
    "  return  train_roc_auc_list, test_roc_auc_list, runtime_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78
    },
    "colab_type": "code",
    "id": "IDyA3Z4sRZPd",
    "outputId": "c2d1a234-4f97-4b9e-b893-d4bbe0d4753a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Capes</th>\n",
       "      <th>Epoques</th>\n",
       "      <th>Pxls_Fil_Col</th>\n",
       "      <th>DropOut</th>\n",
       "      <th>NumMod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model_5</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Capes  Epoques  Pxls_Fil_Col DropOut  NumMod\n",
       "4  Model_5      6       25           100   False       5"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "h_pixels = w_pixels = 100\n",
    "Epoques = 25\n",
    "Capes = np.arange(2, 10, 1)\n",
    "n = len(Capes)\n",
    "\n",
    "NumModel =  np.arange(1, n +1, 1)\n",
    "\n",
    "\n",
    "DropOut = 'False'\n",
    "DataAugmentation = 'False'\n",
    "\n",
    "Model1 = []\n",
    "for index in range(n):\n",
    "    model1 = 'Model_' + str(index + 1)\n",
    "    Model1.append(model1)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "df_AucRoc = { 'Model': Model1, \n",
    "              'Capes': Capes, \n",
    "              'Epoques': Epoques,\n",
    "              'Pxls_Fil_Col': h_pixels,\n",
    "              'DropOut': DropOut,\n",
    "              'NumMod': NumModel,}\n",
    "\n",
    "\n",
    "Param_AUCROC_Conv  = pd.DataFrame(data = df_AucRoc)\n",
    "Param_AUCROC_Conv =  Param_AUCROC_Conv.iloc[4:5]\n",
    "Param_AUCROC_Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1142
    },
    "colab_type": "code",
    "id": "8uW2j8XxYYRn",
    "outputId": "906a66fd-deb7-4c06-aadf-0cf0eb5f60b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#################################################################\n",
      "\t\t MODEL:\t\t5\n",
      "\t\t CAPES:\t\t6\n",
      "\t\t EPOQUES:\t25\n",
      "\t\t PIXELS:\t(100,100)\n",
      "#################################################################\n",
      "\n",
      "Capes 6: (32, 32) + (64, 64) + (128) + FDD\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_47 (Conv2D)           (None, 100, 100, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 98, 98, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 96, 96, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 94, 94, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 92, 92, 128)       73856     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1083392)           0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               277348608 \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 277,487,713\n",
      "Trainable params: 277,487,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "=================================================================\n",
      "      E N T R E N A M E N T     D E L      M O D E L     5\n",
      "                  -----------------------\n",
      "                      Iteraci贸  1 / 2\n",
      "=================================================================\n",
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-5ebebe43b515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                            \u001b[0mw_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPixels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                                            \u001b[0mDropOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropOut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                                                            NumMod = NumMod)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-feceab2058f0>\u001b[0m in \u001b[0;36mDefine_model\u001b[0;34m(capes, epoques, h_pixels, w_pixels, DropOut, NumMod)\u001b[0m\n\u001b[1;32m    159\u001b[0m               \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_steps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m               \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m               epochs = epoques)\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    852\u001b[0m     elif distributed_training_utils.is_tpu_strategy(\n\u001b[1;32m    853\u001b[0m         self._distribution_strategy):\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m-> 1175\u001b[0;31m         x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    351\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_47_input to have 4 dimensions, but got array with shape (100, 100, 1)"
     ]
    }
   ],
   "source": [
    "for i, row in Param_AUCROC_Conv.iterrows():\n",
    "  \n",
    "  Model = row['Model']\n",
    "  Capes = row['Capes']\n",
    "  Epoques = row['Epoques']\n",
    "  Pixels = row['Pxls_Fil_Col']\n",
    "  DropOut = row['DropOut']\n",
    "  NumMod = row['NumMod']\n",
    "  \n",
    "  \n",
    "  auc_train_5, auc_test_5, runtime_model_5 = Define_model( capes =  Capes, \n",
    "                                                           epoques = Epoques, \n",
    "                                                           h_pixels = Pixels,  \n",
    "                                                           w_pixels = Pixels,\n",
    "                                                           DropOut = DropOut,\n",
    "                                                           NumMod = NumMod)\n",
    "\n",
    "\n",
    "   \n",
    "   \n",
    "  \n",
    "  #Eval_AUCROC_Conv_aug.to_csv('/content/gdrive/My Drive/Resultats/Param_Definicio_Model_CAPES_DATA_AUGMENTATION.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Treball_Final_de_Grau_PNEUMONIA.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
